---
layout: post
title: EM 算法
categories: [Machine Learning]
description: EM 算法
keywords: EM
---

EM 算法是一种无监督的聚类方法，本文对其进行一个总结

---

[TOC]

# 概述
EM 算法利用极大似然估计法，对于含有隐变量的模型参数进行迭代估计，每次迭代分为两步：E(expectation)步，求期望；M(maximization)步，求极大值。

# 数学基础
先对EM 算法涉及到的数学基础进行回忆，如果已经掌握可以跳过本部分。

## 极大似然估计
极大似然估计是一种概率论中参数估计方法，常见参数估计方法如下：

![mark](http://pcxhsqn8a.bkt.clouddn.com/blog/181115/Fj40ac0BE3.png?imageslim)

极大似然估计的思想是，现在已经获得样本 $x_{1}$, $x_{2}$, ..., $x_{n}$，表明取到这一组样本的概率比较大，将似然函数$L(\theta)$定义为取到这一组变量的概率，那么通过使似然函数最大所得到的$\hat{\theta}$值，就可以作为参数$\theta$的估计值。

$\hat{\theta}(x_{1}$, $x_{2}$, ..., $x_{n})$ 称为参数$\theta$的最大似然估计值，$\hat{\theta}(x_{1}$, $x_{2}$, ..., $x_{n})$ 称为参数$\theta$的最大似然估计量。












