---
layout: post
title: 学习 LSTM
categories: [Machine Learning]
description: 学习 LSTM
keywords: 学习 LSTM
---

图文并茂

---


## 基本结构

![mark](http://pcxhsqn8a.bkt.clouddn.com/blog/181117/JDc26c3k45.png?imageslim)

RNN、LSTM 解决的问题是序列建模问题，如上图，基本的 RNN 结构只有一个激活函数为 $tanh$ 的层，但是 RNN 目光短浅，只能记忆短期信息，但不能处理长期的信息，这就对一些需要长期依赖的问题束手无策了。我们的 LSTM 通过三个“门”解决了要忘记什么信息、要加入什么信息、要输出什么信息的问题。其结构如下图：

![mark](http://pcxhsqn8a.bkt.clouddn.com/blog/181117/0A29jdhA9m.png?imageslim)

